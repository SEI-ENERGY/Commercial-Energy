{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC - Run experiments\n",
    "\n",
    "In this notebook we run the experiments that are shown in Table 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import CBECSLib\n",
    "CBECSLib = reload(CBECSLib)\n",
    "\n",
    "import itertools\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-paper')\n",
    "\n",
    "#sklearn base\n",
    "import sklearn.base\n",
    "\n",
    "#sklearn utility\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#sklearn models\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.linear_model import Lasso, ElasticNet, SGDRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor, GradientBoostingRegressor, RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "#IPython utilities\n",
    "from IPython.display import HTML,display\n",
    "def show(html):\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RESULTS_DIR = \"results/\" # where output is written to\n",
    "DATASET = \"VAL\" # for the extended set of features use 0, for the common set of features use 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_NYC():\n",
    "    X_val = np.load(\"output/nyc/ll84_X_2016.npy\")\n",
    "    Y_val = np.load(\"output/nyc/ll84_Y_2016.npy\")\n",
    "    valClassVals = np.load(\"output/nyc/ll84_classVals_2016.npy\")\n",
    "    return X_val, Y_val, valClassVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pbaLabels = CBECSLib.pbaLabels\n",
    "pbaPlusLabels = CBECSLib.pbaPlusLabels\n",
    "\n",
    "getClassFrequencies = CBECSLib.getClassFrequencies\n",
    "getDataSubset = CBECSLib.getDataSubset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regressors = [\n",
    "    LinearRegression(n_jobs=-1),\n",
    "    Ridge(),\n",
    "    SVR(),\n",
    "    Lasso(),\n",
    "    ElasticNet(),\n",
    "    LinearSVR(verbose=0),\n",
    "    AdaBoostRegressor(),\n",
    "    BaggingRegressor(n_jobs=-1),\n",
    "    GradientBoostingRegressor(verbose=0),\n",
    "    RandomForestRegressor(n_jobs=-1, verbose=0),\n",
    "    ExtraTreesRegressor(n_jobs=-1, verbose=0),\n",
    "    MLPRegressor(),\n",
    "    KNeighborsRegressor()    \n",
    "]\n",
    "regressorNames = [\n",
    "    \"Linear Regression\",\n",
    "    \"Ridge Regressor\",\n",
    "    \"SVR\",\n",
    "    \"Lasso\",\n",
    "    \"ElasticNet\",\n",
    "    \"Linear SVR\",\n",
    "    \"AdaBoost\",\n",
    "    \"Bagging\",\n",
    "    \"XGBoost\",\n",
    "    \"Random Forest Regressor\",\n",
    "    \"Extra Trees Regressor\",\n",
    "    \"MLP Regressor\",\n",
    "    \"KNN Regressor\"\n",
    "]\n",
    "assert len(regressors) == len(regressorNames)\n",
    "numRegressors = len(regressors)\n",
    "\n",
    "metrics = [\n",
    "    mean_absolute_error,\n",
    "    lambda y_true, y_pred: 10.0 ** mean_absolute_error(y_true, y_pred),\n",
    "    median_absolute_error,\n",
    "    lambda y_true, y_pred: 10.0 ** median_absolute_error(y_true, y_pred),\n",
    "    r2_score,\n",
    "    lambda y_true, y_pred: r2_score(10.0 ** y_true, 10.0 ** y_pred)\n",
    "]\n",
    "metricNames = [\n",
    "    \"Mean Absolute Error\",\n",
    "    \"10^Mean AE\",\n",
    "    \"Median Absolute Error\",\n",
    "    \"10^Median AE\",\n",
    "    \"$r^2$\",\n",
    "    \"$r^2$ linspace\"\n",
    "]\n",
    "assert len(metrics) == len(metricNames)\n",
    "numMetrics = len(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments Training on All Data, Testing on All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 0\n",
      "Repetition 1\n",
      "Repetition 2\n",
      "Repetition 3\n",
      "Repetition 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 5\n",
      "Repetition 6\n",
      "Repetition 7\n",
      "Repetition 8\n",
      "Repetition 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>10^Mean AE</th>\n",
       "      <th>Median Absolute Error</th>\n",
       "      <th>10^Median AE</th>\n",
       "      <th>$r^2$</th>\n",
       "      <th>$r^2$ linspace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>0.29 +/- 0.02</td>\n",
       "      <td>1.96 +/- 0.10</td>\n",
       "      <td>0.19 +/- 0.01</td>\n",
       "      <td>1.56 +/- 0.05</td>\n",
       "      <td>0.44 +/- 0.08</td>\n",
       "      <td>-0.91 +/- 1.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regressor</th>\n",
       "      <td>0.29 +/- 0.02</td>\n",
       "      <td>1.96 +/- 0.10</td>\n",
       "      <td>0.19 +/- 0.01</td>\n",
       "      <td>1.56 +/- 0.05</td>\n",
       "      <td>0.44 +/- 0.08</td>\n",
       "      <td>-0.90 +/- 1.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.25 +/- 0.02</td>\n",
       "      <td>1.77 +/- 0.10</td>\n",
       "      <td>0.15 +/- 0.01</td>\n",
       "      <td>1.40 +/- 0.03</td>\n",
       "      <td>0.51 +/- 0.11</td>\n",
       "      <td>-0.00 +/- 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.45 +/- 0.01</td>\n",
       "      <td>2.80 +/- 0.04</td>\n",
       "      <td>0.33 +/- 0.01</td>\n",
       "      <td>2.13 +/- 0.06</td>\n",
       "      <td>-0.01 +/- 0.00</td>\n",
       "      <td>-0.01 +/- 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>0.45 +/- 0.01</td>\n",
       "      <td>2.80 +/- 0.04</td>\n",
       "      <td>0.33 +/- 0.01</td>\n",
       "      <td>2.13 +/- 0.06</td>\n",
       "      <td>-0.01 +/- 0.00</td>\n",
       "      <td>-0.01 +/- 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVR</th>\n",
       "      <td>0.28 +/- 0.02</td>\n",
       "      <td>1.92 +/- 0.08</td>\n",
       "      <td>0.17 +/- 0.00</td>\n",
       "      <td>1.50 +/- 0.01</td>\n",
       "      <td>0.42 +/- 0.05</td>\n",
       "      <td>-174.15 +/- 246.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.42 +/- 0.07</td>\n",
       "      <td>2.67 +/- 0.43</td>\n",
       "      <td>0.30 +/- 0.04</td>\n",
       "      <td>2.01 +/- 0.20</td>\n",
       "      <td>0.14 +/- 0.22</td>\n",
       "      <td>0.01 +/- 0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.29 +/- 0.02</td>\n",
       "      <td>1.95 +/- 0.09</td>\n",
       "      <td>0.18 +/- 0.01</td>\n",
       "      <td>1.50 +/- 0.04</td>\n",
       "      <td>0.43 +/- 0.08</td>\n",
       "      <td>-0.02 +/- 0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.24 +/- 0.02</td>\n",
       "      <td>1.75 +/- 0.09</td>\n",
       "      <td>0.15 +/- 0.01</td>\n",
       "      <td>1.40 +/- 0.03</td>\n",
       "      <td>0.54 +/- 0.09</td>\n",
       "      <td>-0.01 +/- 0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Regressor</th>\n",
       "      <td>0.29 +/- 0.02</td>\n",
       "      <td>1.95 +/- 0.10</td>\n",
       "      <td>0.18 +/- 0.02</td>\n",
       "      <td>1.51 +/- 0.05</td>\n",
       "      <td>0.43 +/- 0.08</td>\n",
       "      <td>-0.02 +/- 0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extra Trees Regressor</th>\n",
       "      <td>0.30 +/- 0.03</td>\n",
       "      <td>2.00 +/- 0.12</td>\n",
       "      <td>0.18 +/- 0.01</td>\n",
       "      <td>1.51 +/- 0.05</td>\n",
       "      <td>0.39 +/- 0.09</td>\n",
       "      <td>-0.02 +/- 0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP Regressor</th>\n",
       "      <td>0.28 +/- 0.04</td>\n",
       "      <td>1.92 +/- 0.17</td>\n",
       "      <td>0.17 +/- 0.02</td>\n",
       "      <td>1.48 +/- 0.06</td>\n",
       "      <td>0.44 +/- 0.13</td>\n",
       "      <td>-0.44 +/- 1.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN Regressor</th>\n",
       "      <td>0.30 +/- 0.03</td>\n",
       "      <td>2.01 +/- 0.15</td>\n",
       "      <td>0.19 +/- 0.02</td>\n",
       "      <td>1.53 +/- 0.06</td>\n",
       "      <td>0.40 +/- 0.12</td>\n",
       "      <td>-0.00 +/- 0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Mean Absolute Error     10^Mean AE  \\\n",
       "Linear Regression             0.29 +/- 0.02  1.96 +/- 0.10   \n",
       "Ridge Regressor               0.29 +/- 0.02  1.96 +/- 0.10   \n",
       "SVR                           0.25 +/- 0.02  1.77 +/- 0.10   \n",
       "Lasso                         0.45 +/- 0.01  2.80 +/- 0.04   \n",
       "ElasticNet                    0.45 +/- 0.01  2.80 +/- 0.04   \n",
       "Linear SVR                    0.28 +/- 0.02  1.92 +/- 0.08   \n",
       "AdaBoost                      0.42 +/- 0.07  2.67 +/- 0.43   \n",
       "Bagging                       0.29 +/- 0.02  1.95 +/- 0.09   \n",
       "XGBoost                       0.24 +/- 0.02  1.75 +/- 0.09   \n",
       "Random Forest Regressor       0.29 +/- 0.02  1.95 +/- 0.10   \n",
       "Extra Trees Regressor         0.30 +/- 0.03  2.00 +/- 0.12   \n",
       "MLP Regressor                 0.28 +/- 0.04  1.92 +/- 0.17   \n",
       "KNN Regressor                 0.30 +/- 0.03  2.01 +/- 0.15   \n",
       "\n",
       "                        Median Absolute Error   10^Median AE           $r^2$  \\\n",
       "Linear Regression               0.19 +/- 0.01  1.56 +/- 0.05   0.44 +/- 0.08   \n",
       "Ridge Regressor                 0.19 +/- 0.01  1.56 +/- 0.05   0.44 +/- 0.08   \n",
       "SVR                             0.15 +/- 0.01  1.40 +/- 0.03   0.51 +/- 0.11   \n",
       "Lasso                           0.33 +/- 0.01  2.13 +/- 0.06  -0.01 +/- 0.00   \n",
       "ElasticNet                      0.33 +/- 0.01  2.13 +/- 0.06  -0.01 +/- 0.00   \n",
       "Linear SVR                      0.17 +/- 0.00  1.50 +/- 0.01   0.42 +/- 0.05   \n",
       "AdaBoost                        0.30 +/- 0.04  2.01 +/- 0.20   0.14 +/- 0.22   \n",
       "Bagging                         0.18 +/- 0.01  1.50 +/- 0.04   0.43 +/- 0.08   \n",
       "XGBoost                         0.15 +/- 0.01  1.40 +/- 0.03   0.54 +/- 0.09   \n",
       "Random Forest Regressor         0.18 +/- 0.02  1.51 +/- 0.05   0.43 +/- 0.08   \n",
       "Extra Trees Regressor           0.18 +/- 0.01  1.51 +/- 0.05   0.39 +/- 0.09   \n",
       "MLP Regressor                   0.17 +/- 0.02  1.48 +/- 0.06   0.44 +/- 0.13   \n",
       "KNN Regressor                   0.19 +/- 0.02  1.53 +/- 0.06   0.40 +/- 0.12   \n",
       "\n",
       "                             $r^2$ linspace  \n",
       "Linear Regression            -0.91 +/- 1.27  \n",
       "Ridge Regressor              -0.90 +/- 1.26  \n",
       "SVR                          -0.00 +/- 0.00  \n",
       "Lasso                        -0.01 +/- 0.00  \n",
       "ElasticNet                   -0.01 +/- 0.00  \n",
       "Linear SVR               -174.15 +/- 246.72  \n",
       "AdaBoost                      0.01 +/- 0.01  \n",
       "Bagging                      -0.02 +/- 0.07  \n",
       "XGBoost                      -0.01 +/- 0.01  \n",
       "Random Forest Regressor      -0.02 +/- 0.03  \n",
       "Extra Trees Regressor        -0.02 +/- 0.03  \n",
       "MLP Regressor                -0.44 +/- 1.43  \n",
       "KNN Regressor                -0.00 +/- 0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X,Y,classVals = load_NYC()\n",
    "classOrdering,classFrequencies = getClassFrequencies(classVals)\n",
    "numClassVals = len(classFrequencies)\n",
    "\n",
    "numSplits = 3\n",
    "numRepeats = 10\n",
    "outputFn = \"test_all_VAL\"\n",
    "\n",
    "results = np.zeros((numRepeats, numSplits, numRegressors, numMetrics), dtype=float)\n",
    "\n",
    "for i in range(numRepeats):\n",
    "    print \"Repetition %d\" % (i)\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=numSplits)\n",
    "    for j, (train, test) in enumerate(kf.split(X,classVals)):\n",
    "        #print \"\\tSplit %d\" % (j)\n",
    "        X_train, X_test = X[train,:], X[test,:]\n",
    "        Y_train, Y_test = Y[train], Y[test]\n",
    "        classVals_train, classVals_test = classVals[train].copy(), classVals[test].copy()\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        for k in range(numRegressors):\n",
    "            regressor = sklearn.base.clone(regressors[k])\n",
    "            regressorName = regressorNames[k]\n",
    "\n",
    "            #train model\n",
    "            regressor.fit(X_train,Y_train)\n",
    "\n",
    "            #predict model\n",
    "            predicted = regressor.predict(X_test)\n",
    "            predicted[predicted<0] = 0\n",
    "\n",
    "            #evaluate model\n",
    "            for m,metric in enumerate(metrics):\n",
    "                metricName = metricNames[m]\n",
    "                score = metric(Y_test,predicted)\n",
    "                results[i,j,k,m] = score\n",
    "        \n",
    "results = np.array(results)\n",
    "\n",
    "results = results.reshape(-1, numRegressors, numMetrics)\n",
    "\n",
    "classNames = [pbaLabels[pbaLabel] for pbaLabel in classOrdering]\n",
    "\n",
    "meanResults = results.mean(axis=0)\n",
    "meanResultTable = pd.DataFrame(meanResults, index=regressorNames, columns=metricNames)\n",
    "meanResultTable.to_csv(os.path.join(RESULTS_DIR, \"%s_means.csv\" % (outputFn)))\n",
    "\n",
    "stdResults = results.std(axis=0)\n",
    "stdResultTable = pd.DataFrame(stdResults, index=regressorNames, columns=metricNames)\n",
    "stdResultTable.to_csv(os.path.join(RESULTS_DIR, \"%s_stds.csv\" % (outputFn)))\n",
    "\n",
    "formattedResults = []\n",
    "for i in range(numRegressors):\n",
    "    row = []\n",
    "    for j in range(numMetrics):\n",
    "        row.append(\"%0.2f +/- %0.2f\" % (meanResults[i,j], stdResults[i,j]))\n",
    "    formattedResults.append(row)\n",
    "formattedResults = np.array(formattedResults)\n",
    "formattedResultsTable = pd.DataFrame(formattedResults, index=regressorNames, columns=metricNames)\n",
    "formattedResultsTable.to_csv(os.path.join(RESULTS_DIR, \"%s_formatted.csv\" % (outputFn)))\n",
    "\n",
    "display(formattedResultsTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
