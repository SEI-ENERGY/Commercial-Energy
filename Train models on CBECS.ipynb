{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models on CBECS\n",
    "\n",
    "In this notebook we train a model using each model with the \"common feature\" dataset, then save the trained model to disk to be applied elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import cPickle as pickle\n",
    "\n",
    "import CBECSLib\n",
    "\n",
    "import itertools\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-paper')\n",
    "\n",
    "#sklearn base\n",
    "import sklearn.base\n",
    "\n",
    "#sklearn utility\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#sklearn models\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.linear_model import Lasso, ElasticNet, SGDRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor, GradientBoostingRegressor, RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"output/trainedModels/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pbaLabels = CBECSLib.pbaLabels\n",
    "pbaPlusLabels = CBECSLib.pbaPlusLabels\n",
    "\n",
    "getDataset = CBECSLib.getDataset\n",
    "getClassFrequencies = CBECSLib.getClassFrequencies\n",
    "getDataSubset = CBECSLib.getDataSubset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regressors = [\n",
    "    LinearRegression(n_jobs=-1),\n",
    "    Ridge(),\n",
    "    SVR(),\n",
    "    Lasso(),\n",
    "    ElasticNet(),\n",
    "    LinearSVR(verbose=0),\n",
    "    AdaBoostRegressor(),\n",
    "    BaggingRegressor(n_jobs=-1),\n",
    "    GradientBoostingRegressor(verbose=0),\n",
    "    RandomForestRegressor(n_jobs=-1, verbose=0),\n",
    "    ExtraTreesRegressor(n_jobs=-1, verbose=0),\n",
    "    MLPRegressor(),\n",
    "    KNeighborsRegressor()    \n",
    "]\n",
    "regressorNames = [\n",
    "    \"Linear Regression\",\n",
    "    \"Ridge Regressor\",\n",
    "    \"SVR\",\n",
    "    \"Lasso\",\n",
    "    \"ElasticNet\",\n",
    "    \"Linear SVR\",\n",
    "    \"AdaBoost\",\n",
    "    \"Bagging\",\n",
    "    \"XGBoost\",\n",
    "    \"Random Forest Regressor\",\n",
    "    \"Extra Trees Regressor\",\n",
    "    \"MLP Regressor\",\n",
    "    \"KNN Regressor\"\n",
    "]\n",
    "assert len(regressors) == len(regressorNames)\n",
    "numRegressors = len(regressors)\n",
    "\n",
    "metrics = [\n",
    "    mean_absolute_error,\n",
    "    median_absolute_error,\n",
    "    r2_score\n",
    "]\n",
    "metricNames = [\n",
    "    \"Mean Absolute Error\",\n",
    "    \"Median Absolute Error\",\n",
    "    \"$r^2$\"\n",
    "]\n",
    "assert len(metrics) == len(metricNames)\n",
    "numMetrics = len(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create regression models and save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 classes\n",
      "['SQFT' 'CDD65' 'HDD65' 'NFLOOR' 'PBA 1' 'PBA 2' 'PBA 4' 'PBA 5' 'PBA 6'\n",
      " 'PBA 7' 'PBA 8' 'PBA 11' 'PBA 12' 'PBA 13' 'PBA 14' 'PBA 15' 'PBA 16'\n",
      " 'PBA 17' 'PBA 18' 'PBA 23' 'PBA 24' 'PBA 25' 'PBA 26' 'PBA 91']\n",
      "Linear Regression\n",
      "[0.51971655364473335, 0.43036557994203406, 0.53846385539177355]\n",
      "Ridge Regressor\n",
      "[0.51963978624712637, 0.42993141750412622, 0.53846473730738165]\n",
      "SVR\n",
      "[0.37184666793365806, 0.27371489175351105, 0.72203247138834037]\n",
      "Lasso\n",
      "[0.78991319184111575, 0.68863716581377776, 0.0]\n",
      "ElasticNet\n",
      "[0.75934058596935938, 0.67488148136559722, 0.09159617864103442]\n",
      "Linear SVR\n",
      "[0.51107883326645631, 0.40115581898317831, 0.52337611975820342]\n",
      "AdaBoost\n",
      "[0.4260757246434117, 0.35264559072645252, 0.69808947298507174]\n",
      "Bagging\n",
      "[0.12735688552502897, 0.084665878478815237, 0.96230346612125273]\n",
      "XGBoost\n",
      "[0.28082793107345938, 0.20933714692904815, 0.84102974263036745]\n",
      "Random Forest Regressor\n",
      "[0.1286557187819253, 0.084340734999310385, 0.96005531274259925]\n",
      "Extra Trees Regressor\n",
      "[2.9435790489464167e-07, 8.8817841970012523e-16, 0.99999999998464639]\n",
      "MLP Regressor\n",
      "[0.30498344613763878, 0.22687103519659768, 0.81052944976850583]\n",
      "KNN Regressor\n",
      "[0.3416189717663804, 0.25501686857694228, 0.77673716159084716]\n"
     ]
    }
   ],
   "source": [
    "X,Y,columnNames,classVals = getDataset(1,pbaOneHot=True)\n",
    "print columnNames\n",
    "classOrdering,classFrequencies = getClassFrequencies(classVals)\n",
    "numClassVals = len(classFrequencies)\n",
    "Y = np.log10(Y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "pickle.dump(scaler, open(\"output/scaler.p\", \"wb\"))\n",
    "\n",
    "for i in range(numRegressors):\n",
    "    regressor = sklearn.base.clone(regressors[i])\n",
    "    regressorName = regressorNames[i]\n",
    "\n",
    "    print regressorName\n",
    "    \n",
    "    #train model\n",
    "    regressor.fit(X_scaled,Y)\n",
    "\n",
    "    #predict model\n",
    "    predicted = regressor.predict(X_scaled)\n",
    "    predicted[predicted<0] = 0\n",
    "\n",
    "    #evaluate model\n",
    "    scores = []\n",
    "    for m,metric in enumerate(metrics):\n",
    "        metricName = metricNames[m]\n",
    "        score = metric(Y,predicted)\n",
    "        scores.append(score)\n",
    "    print scores\n",
    "        \n",
    "    pickle.dump(regressor, open(os.path.join(OUTPUT_DIR, \"%s_trained.p\" % (regressorName)), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
